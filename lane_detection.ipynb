{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lane detection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPZ5YGSRhJ8+lQ9LSvvgvre",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preeyam2000sahu/Lanedetect/blob/main/lane_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "176ewym0Rb7V"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "# from Line import Line"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwApJ6gwR7Bj"
      },
      "source": [
        "The next block of code applies an image mask.\n",
        "    Only keeps the region of the image defined by the polygon\n",
        "    formed from `vertices`. The rest of the image is set to black."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgXMkEzAR5Fz"
      },
      "source": [
        "def region_of_interest(img, vertices):\n",
        "   \n",
        "\n",
        "    # defining a blank mask to start with\n",
        "    mask = np.zeros_like(img)\n",
        "\n",
        "    # defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
        "    if len(img.shape) > 2:\n",
        "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
        "        ignore_mask_color = (255,) * channel_count\n",
        "    else:\n",
        "        ignore_mask_color = 255\n",
        "\n",
        "    # filling pixels inside the polygon defined by \"vertices\" with the fill color\n",
        "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
        "\n",
        "    # returning the image only where mask pixels are nonzero\n",
        "    masked_image = cv2.bitwise_and(img, mask)\n",
        "\n",
        "    return masked_image, mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hYGLa1PSS4o"
      },
      "source": [
        "Canny transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyyseaTVSNge"
      },
      "source": [
        "def hough_lines_detection(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
        "    \n",
        "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len,\n",
        "                            maxLineGap=max_line_gap)\n",
        "    return lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztcWPq9RSfEy"
      },
      "source": [
        " The next function returns the  blend image computed as:\n",
        "    initial_img * α + img * β + λ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hXjzwsYSZah"
      },
      "source": [
        "ef weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
        "    \n",
        "    img = np.uint8(img)\n",
        "    if len(img.shape) is 2:\n",
        "        img = np.dstack((img, np.zeros_like(img), np.zeros_like(img)))\n",
        "\n",
        "    return cv2.addWeighted(initial_img, α, img, β, λ)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EAkOc9bSs-E"
      },
      "source": [
        "\n",
        "THe next function computes lines that approximate the position of both road lanes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vddi7-i6Sure"
      },
      "source": [
        "def compute_lane_from_candidates(line_candidates, img_shape):\n",
        "   \n",
        "\n",
        "    # separate candidate lines according to their slope\n",
        "    pos_lines = [l for l in line_candidates if l.slope > 0]\n",
        "    neg_lines = [l for l in line_candidates if l.slope < 0]\n",
        "\n",
        "    # interpolate biases and slopes to compute equation of line that approximates left lane\n",
        "    # median is employed to filter outliers\n",
        "    neg_bias = np.median([l.bias for l in neg_lines]).astype(int)\n",
        "    neg_slope = np.median([l.slope for l in neg_lines])\n",
        "    x1, y1 = 0, neg_bias\n",
        "    x2, y2 = -np.int32(np.round(neg_bias / neg_slope)), 0\n",
        "    left_lane = Line(x1, y1, x2, y2)\n",
        "\n",
        "    lane_right_bias = np.median([l.bias for l in pos_lines]).astype(int)\n",
        "    lane_right_slope = np.median([l.slope for l in pos_lines])\n",
        "    x1, y1 = 0, lane_right_bias\n",
        "    x2, y2 = np.int32(np.round((img_shape[0] - lane_right_bias) / lane_right_slope)), img_shape[0]\n",
        "    right_lane = Line(x1, y1, x2, y2)\n",
        "\n",
        "    return left_lane, right_lane    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poYcXWTHTK48"
      },
      "source": [
        "def get_lane_lines(color_image, solid_lines=True):\n",
        "   \n",
        "   \n",
        "    color_image = cv2.resize(color_image, (960, 540))\n",
        "\n",
        "   \n",
        "    img_gray = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    \n",
        "    img_blur = cv2.GaussianBlur(img_gray, (17, 17), 0)\n",
        "\n",
        "    # perform edge detection\n",
        "    img_edge = cv2.Canny(img_blur, threshold1=50, threshold2=80)\n",
        "\n",
        "    # perform hough transform\n",
        "    detected_lines = hough_lines_detection(img=img_edge,\n",
        "                                           rho=2,\n",
        "                                           theta=np.pi / 180,\n",
        "                                           threshold=1,\n",
        "                                           min_line_len=15,\n",
        "                                           max_line_gap=5)\n",
        "\n",
        "    \n",
        "    detected_lines = [Line(l[0][0], l[0][1], l[0][2], l[0][3]) for l in detected_lines]\n",
        "\n",
        "    # if 'solid_lines' infer the two lane lines\n",
        "    if solid_lines:\n",
        "        candidate_lines = []\n",
        "        for line in detected_lines:\n",
        "                # consider only lines with slope between 30 and 60 degrees\n",
        "                if 0.5 <= np.abs(line.slope) <= 2:\n",
        "                    candidate_lines.append(line)\n",
        "       \n",
        "        lane_lines = compute_lane_from_candidates(candidate_lines, img_gray.shape)\n",
        "    else:\n",
        "        # if not solid_lines, just return the hough transform output\n",
        "        lane_lines = detected_lines\n",
        "\n",
        "    return lane_lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0KFjRAKTbfQ"
      },
      "source": [
        "def smoothen_over_time(lane_lines):\n",
        "    \"\"\"\n",
        "    Smooth the lane line inference over a window of frames and returns the average lines.\n",
        "    \"\"\"\n",
        "\n",
        "    avg_line_lt = np.zeros((len(lane_lines), 4))\n",
        "    avg_line_rt = np.zeros((len(lane_lines), 4))\n",
        "\n",
        "    for t in range(0, len(lane_lines)):\n",
        "        avg_line_lt[t] += lane_lines[t][0].get_coords()\n",
        "        avg_line_rt[t] += lane_lines[t][1].get_coords()\n",
        "\n",
        "    return Line(*np.mean(avg_line_lt, axis=0)), Line(*np.mean(avg_line_rt, axis=0))\n",
        "\n",
        "\n",
        "def color_frame_pipeline(frames, solid_lines=True, temporal_smoothing=True):\n",
        "    \"\"\"\n",
        "    Entry point for lane detection pipeline. Takes as input a list of frames (RGB) and returns an image (RGB)\n",
        "    with overlaid the inferred road lanes. Eventually, len(frames)==1 in the case of a single image.\n",
        "    \"\"\"\n",
        "    is_videoclip = len(frames) > 0\n",
        "\n",
        "    img_h, img_w = frames[0].shape[0], frames[0].shape[1]\n",
        "\n",
        "    lane_lines = []\n",
        "    for t in range(0, len(frames)):\n",
        "        inferred_lanes = get_lane_lines(color_image=frames[t], solid_lines=solid_lines)\n",
        "        lane_lines.append(inferred_lanes)\n",
        "\n",
        "    if temporal_smoothing and solid_lines:\n",
        "        lane_lines = smoothen_over_time(lane_lines)\n",
        "    else:\n",
        "        lane_lines = lane_lines[0]\n",
        "\n",
        "    # prepare empty mask on which lines are drawn\n",
        "    line_img = np.zeros(shape=(img_h, img_w))\n",
        "\n",
        "    # draw lanes found\n",
        "    for lane in lane_lines:\n",
        "        lane.draw(line_img)\n",
        "\n",
        "    # keep only region of interest by masking\n",
        "    vertices = np.array([[(50, img_h),\n",
        "                          (450, 310),\n",
        "                          (490, 310),\n",
        "                          (img_w - 50, img_h)]],\n",
        "                        dtype=np.int32)\n",
        "    img_masked, _ = region_of_interest(line_img, vertices)\n",
        "\n",
        "    # make blend on color image\n",
        "    img_color = frames[-1] if is_videoclip else frames[0]\n",
        "    img_blend = weighted_img(img_masked, img_color, α=0.8, β=1., λ=0.)\n",
        "\n",
        "    return img_blend\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}